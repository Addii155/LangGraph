{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bafec2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph , START , END\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import TypedDict , Literal\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0755101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09a9dcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class evaulateSchema(BaseModel):\n",
    "\n",
    "    evaluation: Literal[\"approved\", \"need_improvement\"]\n",
    "    feedback: str\n",
    "\n",
    "evaulation_structure = model.with_structured_output(evaulateSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcc579af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetState(TypedDict):\n",
    "\n",
    "    topic: str\n",
    "    tweet: str\n",
    "    evaluation: Literal[\"approved\", \"need_improvement\"]\n",
    "    feedback: str\n",
    "    iteration: int\n",
    "    max_iterations: int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ae1724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state: TweetState):\n",
    "     # prompt\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a funny and clever Twitter/X influencer.\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "    Write a short, original, and hilarious tweet on the topic: \"{state['topic']}\".\n",
    "\n",
    "    Rules:\n",
    "    - Do NOT use question-answer format.\n",
    "    - Max 280 characters.\n",
    "    - Use observational humor, irony, sarcasm, or cultural references.\n",
    "    - Think in meme logic, punchlines, or relatable takes.\n",
    "    - Use simple, day to day english\n",
    "    - Avoid cliches, platitudes, or generic humor.\n",
    "    - Make it shareable and engaging.\n",
    "    \"\"\")\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\n",
    "        \"tweet\": response.content}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fa837c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(state: TweetState):\n",
    "    messages = [\n",
    "    SystemMessage(content=\"You are a ruthless, no-laugh-given Twitter critic. You evaluate tweets based on humor, originality, virality, and tweet format.\"),\n",
    "    HumanMessage(content=f\"\"\"\n",
    "    Evaluate the following tweet:\n",
    "\n",
    "    Tweet: \"{state['tweet']}\"\n",
    "\n",
    "    Use the criteria below to evaluate the tweet:\n",
    "\n",
    "    1. Originality – Is this fresh, or have you seen it a hundred times before?  \n",
    "    2. Humor – Did it genuinely make you smile, laugh, or chuckle?  \n",
    "    3. Punchiness – Is it short, sharp, and scroll-stopping?  \n",
    "    4. Virality Potential – Would people retweet or share it?  \n",
    "    5. Format – Is it a well-formed tweet (not a setup-punchline joke, not a Q&A joke, and under 280 characters)?\n",
    "\n",
    "    Auto-reject if:\n",
    "    - It's written in question-answer format (e.g., \"Why did...\" or \"What happens when...\")\n",
    "    - It exceeds 280 characters\n",
    "    - It reads like a traditional setup-punchline joke\n",
    "    - Dont end with generic, throwaway, or deflating lines that weaken the humor (e.g., “Masterpieces of the auntie-uncle universe” or vague summaries)\n",
    "\n",
    "    ### Respond ONLY in structured format:\n",
    "    - evaluation: \"approved\" or \"needs_improvement\"  \n",
    "    - feedback: One paragraph explaining the strengths and weaknesses \n",
    "    \"\"\")\n",
    "    ]\n",
    "    response = evaulation_structure.invoke(messages)\n",
    "    return {\n",
    "        \"evaluation\": response.evaluation,\n",
    "        \"feedback\": response.feedback\n",
    "    }\n",
    "def improve(state: TweetState):\n",
    "     \n",
    "    messages = [\n",
    "    SystemMessage(content=\"You punch up tweets for virality and humor based on given feedback.\"),\n",
    "    HumanMessage(content=f\"\"\"\n",
    "    Improve the tweet based on this feedback:\n",
    "    \"{state['feedback']}\"\n",
    "\n",
    "    Topic: \"{state['topic']}\"\n",
    "    Original Tweet:\n",
    "    {state['tweet']}\n",
    "\n",
    "    Re-write it as a short, viral-worthy tweet. Avoid Q&A style and stay under 280 characters.\n",
    "    \"\"\")\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\n",
    "        \"tweet\": response.content,\n",
    "        \"iteration\": state['iteration'] + 1\n",
    "    } if state['iteration'] < state['max_iterations'] else END\n",
    "\n",
    "\n",
    "def route_evaluation(state: TweetState):\n",
    "    if state['evaluation'] == \"approved\":\n",
    "        return END\n",
    "    else:\n",
    "        return 'improve'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf289344",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(TweetState)\n",
    "graph.add_node('generate', generate)\n",
    "graph.add_node('evaluate', evaluate)\n",
    "graph.add_node('improve', improve)\n",
    "\n",
    "graph.add_edge(START,'generate')\n",
    "graph.add_edge('generate', 'evaluate')\n",
    "graph.add_conditional_edges('evaluate', route_evaluation )\n",
    "\n",
    "workflow = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf71a2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'grtrtert',\n",
       " 'tweet': 'My autocorrect just changed \"grtrtert\" to \"greater tert.\"  I\\'m pretty sure my phone is judging my life choices. #autocorrectfail #existentialcrisis #sendhelp',\n",
       " 'evaluation': 'approved',\n",
       " 'feedback': \"The tweet is mildly amusing due to the relatable nature of autocorrect errors and the humorous interpretation of the phone judging life choices. The inclusion of relevant hashtags increases virality potential. However, the originality is somewhat low, as autocorrect fails are a common theme on social media. The tweet's length is appropriate, and its format is suitable for Twitter.  While it might not be laugh-out-loud funny, it has enough appeal to garner some engagement.\",\n",
       " 'iteration': 0,\n",
       " 'max_iterations': 3}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state = {\n",
    "    \"topic\":\"grtrtert\"\n",
    "    , \"iteration\": 0, \"max_iterations\": 3, \"tweet\": \"\", \"evaluation\": \"need_improvement\", \"feedback\": \"\"\n",
    "}\n",
    "\n",
    "workflow.invoke(initial_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
